{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><font color=yellow><i> Deep Learning </i></font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Import$ $Libraries$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Data$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 1:</font></b>\n",
    " \n",
    "- Import **data** (pandas dataframe). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_semicolon</th>\n",
       "      <th>char_freq_leftbrac</th>\n",
       "      <th>char_freq_leftsquarebrac</th>\n",
       "      <th>char_freq_exclaim</th>\n",
       "      <th>char_freq_dollar</th>\n",
       "      <th>char_freq_pound</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_semicolon  \\\n",
       "0             0.00            0.00  ...                 0.00   \n",
       "1             0.00            0.94  ...                 0.00   \n",
       "2             0.64            0.25  ...                 0.01   \n",
       "3             0.31            0.63  ...                 0.00   \n",
       "4             0.31            0.63  ...                 0.00   \n",
       "\n",
       "   char_freq_leftbrac  char_freq_leftsquarebrac  char_freq_exclaim  \\\n",
       "0               0.000                       0.0              0.778   \n",
       "1               0.132                       0.0              0.372   \n",
       "2               0.143                       0.0              0.276   \n",
       "3               0.137                       0.0              0.137   \n",
       "4               0.135                       0.0              0.135   \n",
       "\n",
       "   char_freq_dollar  char_freq_pound  capital_run_length_average  \\\n",
       "0             0.000            0.000                       3.756   \n",
       "1             0.180            0.048                       5.114   \n",
       "2             0.184            0.010                       9.821   \n",
       "3             0.000            0.000                       3.537   \n",
       "4             0.000            0.000                       3.537   \n",
       "\n",
       "   capital_run_length_longest  capital_run_length_total  spam  \n",
       "0                          61                       278     1  \n",
       "1                         101                      1028     1  \n",
       "2                         485                      2259     1  \n",
       "3                          40                       191     1  \n",
       "4                          40                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam=pd.read_csv('spam.csv')\n",
    "df_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 2:</font></b>\n",
    " \n",
    "- Separate the output (the column `spam`) and the input (the other columns). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_spam['spam']\n",
    "X=df_spam.drop('spam',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_semicolon</th>\n",
       "      <th>char_freq_leftbrac</th>\n",
       "      <th>char_freq_leftsquarebrac</th>\n",
       "      <th>char_freq_exclaim</th>\n",
       "      <th>char_freq_dollar</th>\n",
       "      <th>char_freq_pound</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_conference  \\\n",
       "0             0.00            0.00  ...                   0.0   \n",
       "1             0.00            0.94  ...                   0.0   \n",
       "2             0.64            0.25  ...                   0.0   \n",
       "3             0.31            0.63  ...                   0.0   \n",
       "4             0.31            0.63  ...                   0.0   \n",
       "\n",
       "   char_freq_semicolon  char_freq_leftbrac  char_freq_leftsquarebrac  \\\n",
       "0                 0.00               0.000                       0.0   \n",
       "1                 0.00               0.132                       0.0   \n",
       "2                 0.01               0.143                       0.0   \n",
       "3                 0.00               0.137                       0.0   \n",
       "4                 0.00               0.135                       0.0   \n",
       "\n",
       "   char_freq_exclaim  char_freq_dollar  char_freq_pound  \\\n",
       "0              0.778             0.000            0.000   \n",
       "1              0.372             0.180            0.048   \n",
       "2              0.276             0.184            0.010   \n",
       "3              0.137             0.000            0.000   \n",
       "4              0.135             0.000            0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  \n",
       "0                       278  \n",
       "1                      1028  \n",
       "2                      2259  \n",
       "3                       191  \n",
       "4                       191  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 3:</font></b>\n",
    " \n",
    "- Split our data into **train data** (80% -- 3680 rows) and **test data** (921 rows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Building$ $our$ $Model$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 1:</font></b>\n",
    " \n",
    "- Creation of our model using **Keras**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(100, activation='relu', input_shape=[57], name='hidden_layer1'),\n",
    "    layers.Dropout(0.3),  # Ajout d'une couche Dropout pour réduire le surajustement\n",
    "    layers.Dense(100, activation='relu', name='hidden_layer2'),\n",
    "    layers.Dropout(0.3),  # Ajout d'une couche Dropout pour réduire le surajustement\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1, activation='sigmoid', name='output_layer'),  # Changement de l'activation en 'sigmoid'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer1 (Dense)       (None, 100)               5800      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,401\n",
      "Trainable params: 16,201\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 2:</font></b>\n",
    " \n",
    "- Precise the `optimizer`, the `loss-fonction` & the `metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 3:</font></b>\n",
    " \n",
    "- Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ELITEBOOK\\anaconda3\\envs\\ner\\lib\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 2s 8ms/step - loss: 0.6827 - accuracy: 0.6732 - val_loss: 0.5720 - val_accuracy: 0.7106\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.7011 - val_loss: 0.5716 - val_accuracy: 0.6984\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.7018 - val_loss: 0.5636 - val_accuracy: 0.7011\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.7123 - val_loss: 0.5694 - val_accuracy: 0.6929\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7184 - val_loss: 0.5815 - val_accuracy: 0.6644\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.5434 - accuracy: 0.7242 - val_loss: 0.5671 - val_accuracy: 0.6726\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7289 - val_loss: 0.5307 - val_accuracy: 0.7065\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7503 - val_loss: 0.5709 - val_accuracy: 0.6576\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7677 - val_loss: 0.5280 - val_accuracy: 0.6929\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7799 - val_loss: 0.5070 - val_accuracy: 0.7092\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7870 - val_loss: 0.4991 - val_accuracy: 0.7065\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5186 - val_accuracy: 0.6698\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8274 - val_loss: 0.5117 - val_accuracy: 0.6685\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8319 - val_loss: 0.5069 - val_accuracy: 0.6658\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8478 - val_loss: 0.3820 - val_accuracy: 0.8261\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8560 - val_loss: 0.4082 - val_accuracy: 0.7880\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8567 - val_loss: 0.3796 - val_accuracy: 0.8220\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8716 - val_loss: 0.4178 - val_accuracy: 0.7649\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.3020 - accuracy: 0.8818 - val_loss: 0.3567 - val_accuracy: 0.8492\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2879 - accuracy: 0.8774 - val_loss: 0.3890 - val_accuracy: 0.7989\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.8872 - val_loss: 0.3432 - val_accuracy: 0.8505\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2672 - accuracy: 0.8916 - val_loss: 0.3232 - val_accuracy: 0.8628\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.8944 - val_loss: 0.2834 - val_accuracy: 0.8995\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2618 - accuracy: 0.9005 - val_loss: 0.2744 - val_accuracy: 0.9035\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.8978 - val_loss: 0.2515 - val_accuracy: 0.9266\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2435 - accuracy: 0.9073 - val_loss: 0.2590 - val_accuracy: 0.9266\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2364 - accuracy: 0.9117 - val_loss: 0.2648 - val_accuracy: 0.9239\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 0.2481 - accuracy: 0.9059 - val_loss: 0.2628 - val_accuracy: 0.9226\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2451 - accuracy: 0.9059 - val_loss: 0.2510 - val_accuracy: 0.9226\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9161 - val_loss: 0.2238 - val_accuracy: 0.9361\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2246 - accuracy: 0.9205 - val_loss: 0.2426 - val_accuracy: 0.9239\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2253 - accuracy: 0.9198 - val_loss: 0.2082 - val_accuracy: 0.9293\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2190 - accuracy: 0.9124 - val_loss: 0.2129 - val_accuracy: 0.9375\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.2224 - accuracy: 0.9164 - val_loss: 0.2126 - val_accuracy: 0.9226\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2183 - accuracy: 0.9181 - val_loss: 0.2106 - val_accuracy: 0.9375\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2081 - accuracy: 0.9195 - val_loss: 0.2067 - val_accuracy: 0.9375\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9185 - val_loss: 0.2019 - val_accuracy: 0.9321\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2131 - accuracy: 0.9229 - val_loss: 0.2342 - val_accuracy: 0.9226\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1941 - accuracy: 0.9300 - val_loss: 0.2104 - val_accuracy: 0.9334\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9290 - val_loss: 0.2084 - val_accuracy: 0.9402\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1973 - accuracy: 0.9290 - val_loss: 0.1949 - val_accuracy: 0.9402\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2050 - accuracy: 0.9229 - val_loss: 0.2046 - val_accuracy: 0.9334\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 0.1951 - accuracy: 0.9310 - val_loss: 0.1936 - val_accuracy: 0.9416\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.2043 - accuracy: 0.9310 - val_loss: 0.1948 - val_accuracy: 0.9402\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1914 - accuracy: 0.9331 - val_loss: 0.1855 - val_accuracy: 0.9429\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.9321 - val_loss: 0.2078 - val_accuracy: 0.9416\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1973 - accuracy: 0.9310 - val_loss: 0.1822 - val_accuracy: 0.9429\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1835 - accuracy: 0.9348 - val_loss: 0.2073 - val_accuracy: 0.9348\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1912 - accuracy: 0.9293 - val_loss: 0.2002 - val_accuracy: 0.9429\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.9351 - val_loss: 0.1894 - val_accuracy: 0.9416\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,\n",
    "                 y_train,\n",
    "                 batch_size=32,\n",
    "                 epochs=50,\n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>PS :</font></b> The accuracy of our model on the validation data is **94%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Evaluate$ $Our$ $Model$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 1:</font></b>\n",
    " \n",
    "- Transform our data into a numpy/list data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 2:</font></b>\n",
    " \n",
    "- Evaluate our model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2391 - accuracy: 0.9175\n",
      "Loss on test data: 0.23906409740447998\n",
      "Accuracy on test data: 0.917481005191803\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Loss on test data:', loss)\n",
    "print('Accuracy on test data:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Predict$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "Predicted probabilities: [[0.9874751 ]\n",
      " [0.06729733]\n",
      " [0.9388834 ]\n",
      " [0.03469773]\n",
      " [0.9898854 ]\n",
      " [0.13675955]\n",
      " [0.58683306]\n",
      " [0.00443775]\n",
      " [0.73768014]\n",
      " [0.97575635]]\n",
      "Predicted labels: [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for each class\n",
    "predictions_proba = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to predicted labels (0 or 1 in this binary classification case)\n",
    "predictions = (predictions_proba > 0.5).astype(int)\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predicted probabilities:\", predictions_proba[:10])  # Display the predicted probabilities for the first 10 samples\n",
    "print(\"Predicted labels:\", predictions[:10])  # Display the predicted labels for the first 10 samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
