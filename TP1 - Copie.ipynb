{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><font color=yellow><i> Deep Learning </i></font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Import$ $Libraries$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Data$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 1:</font></b>\n",
    " \n",
    "- Import **data** (pandas dataframe). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_semicolon</th>\n",
       "      <th>char_freq_leftbrac</th>\n",
       "      <th>char_freq_leftsquarebrac</th>\n",
       "      <th>char_freq_exclaim</th>\n",
       "      <th>char_freq_dollar</th>\n",
       "      <th>char_freq_pound</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_semicolon  \\\n",
       "0             0.00            0.00  ...                 0.00   \n",
       "1             0.00            0.94  ...                 0.00   \n",
       "2             0.64            0.25  ...                 0.01   \n",
       "3             0.31            0.63  ...                 0.00   \n",
       "4             0.31            0.63  ...                 0.00   \n",
       "\n",
       "   char_freq_leftbrac  char_freq_leftsquarebrac  char_freq_exclaim  \\\n",
       "0               0.000                       0.0              0.778   \n",
       "1               0.132                       0.0              0.372   \n",
       "2               0.143                       0.0              0.276   \n",
       "3               0.137                       0.0              0.137   \n",
       "4               0.135                       0.0              0.135   \n",
       "\n",
       "   char_freq_dollar  char_freq_pound  capital_run_length_average  \\\n",
       "0             0.000            0.000                       3.756   \n",
       "1             0.180            0.048                       5.114   \n",
       "2             0.184            0.010                       9.821   \n",
       "3             0.000            0.000                       3.537   \n",
       "4             0.000            0.000                       3.537   \n",
       "\n",
       "   capital_run_length_longest  capital_run_length_total  spam  \n",
       "0                          61                       278     1  \n",
       "1                         101                      1028     1  \n",
       "2                         485                      2259     1  \n",
       "3                          40                       191     1  \n",
       "4                          40                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam=pd.read_csv('spam.csv')\n",
    "df_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 2:</font></b>\n",
    " \n",
    "- Separate the output (the column `spam`) and the input (the other columns). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_spam['spam']\n",
    "X=df_spam.drop('spam',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_semicolon</th>\n",
       "      <th>char_freq_leftbrac</th>\n",
       "      <th>char_freq_leftsquarebrac</th>\n",
       "      <th>char_freq_exclaim</th>\n",
       "      <th>char_freq_dollar</th>\n",
       "      <th>char_freq_pound</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_conference  \\\n",
       "0             0.00            0.00  ...                   0.0   \n",
       "1             0.00            0.94  ...                   0.0   \n",
       "2             0.64            0.25  ...                   0.0   \n",
       "3             0.31            0.63  ...                   0.0   \n",
       "4             0.31            0.63  ...                   0.0   \n",
       "\n",
       "   char_freq_semicolon  char_freq_leftbrac  char_freq_leftsquarebrac  \\\n",
       "0                 0.00               0.000                       0.0   \n",
       "1                 0.00               0.132                       0.0   \n",
       "2                 0.01               0.143                       0.0   \n",
       "3                 0.00               0.137                       0.0   \n",
       "4                 0.00               0.135                       0.0   \n",
       "\n",
       "   char_freq_exclaim  char_freq_dollar  char_freq_pound  \\\n",
       "0              0.778             0.000            0.000   \n",
       "1              0.372             0.180            0.048   \n",
       "2              0.276             0.184            0.010   \n",
       "3              0.137             0.000            0.000   \n",
       "4              0.135             0.000            0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  \n",
       "0                       278  \n",
       "1                      1028  \n",
       "2                      2259  \n",
       "3                       191  \n",
       "4                       191  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_semicolon</th>\n",
       "      <th>char_freq_leftbrac</th>\n",
       "      <th>char_freq_leftsquarebrac</th>\n",
       "      <th>char_freq_exclaim</th>\n",
       "      <th>char_freq_dollar</th>\n",
       "      <th>char_freq_pound</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285735</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  word_freq_conference  \\\n",
       "count      4601.000000     4601.000000  ...           4601.000000   \n",
       "mean          0.090067        0.239413  ...              0.031869   \n",
       "std           0.278616        0.644755  ...              0.285735   \n",
       "min           0.000000        0.000000  ...              0.000000   \n",
       "25%           0.000000        0.000000  ...              0.000000   \n",
       "50%           0.000000        0.000000  ...              0.000000   \n",
       "75%           0.000000        0.160000  ...              0.000000   \n",
       "max           5.260000       18.180000  ...             10.000000   \n",
       "\n",
       "       char_freq_semicolon  char_freq_leftbrac  char_freq_leftsquarebrac  \\\n",
       "count          4601.000000         4601.000000               4601.000000   \n",
       "mean              0.038575            0.139030                  0.016976   \n",
       "std               0.243471            0.270355                  0.109394   \n",
       "min               0.000000            0.000000                  0.000000   \n",
       "25%               0.000000            0.000000                  0.000000   \n",
       "50%               0.000000            0.065000                  0.000000   \n",
       "75%               0.000000            0.188000                  0.000000   \n",
       "max               4.385000            9.752000                  4.081000   \n",
       "\n",
       "       char_freq_exclaim  char_freq_dollar  char_freq_pound  \\\n",
       "count        4601.000000       4601.000000      4601.000000   \n",
       "mean            0.269071          0.075811         0.044238   \n",
       "std             0.815672          0.245882         0.429342   \n",
       "min             0.000000          0.000000         0.000000   \n",
       "25%             0.000000          0.000000         0.000000   \n",
       "50%             0.000000          0.000000         0.000000   \n",
       "75%             0.315000          0.052000         0.000000   \n",
       "max            32.478000          6.003000        19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total  \n",
       "count               4601.000000  \n",
       "mean                 283.289285  \n",
       "std                  606.347851  \n",
       "min                    1.000000  \n",
       "25%                   35.000000  \n",
       "50%                   95.000000  \n",
       "75%                  266.000000  \n",
       "max                15841.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
       "       'word_freq_our', 'word_freq_over', 'word_freq_remove',\n",
       "       'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
       "       'word_freq_receive', 'word_freq_will', 'word_freq_people',\n",
       "       'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
       "       'word_freq_business', 'word_freq_email', 'word_freq_you',\n",
       "       'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000',\n",
       "       'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n",
       "       'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n",
       "       'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
       "       'word_freq_technology', 'word_freq_1999', 'word_freq_parts',\n",
       "       'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n",
       "       'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
       "       'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
       "       'char_freq_semicolon', 'char_freq_leftbrac', 'char_freq_leftsquarebrac',\n",
       "       'char_freq_exclaim', 'char_freq_dollar', 'char_freq_pound',\n",
       "       'capital_run_length_average', 'capital_run_length_longest',\n",
       "       'capital_run_length_total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 3:</font></b>\n",
    " \n",
    "- Split our data into **train data** (80% -- 3680 rows) and **test data** (921 rows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $DNN$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Building$ $our$ $Model$ : (Keras sans optimization des hyperparamÃ¨tres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 1:</font></b>\n",
    " \n",
    "- Creation of our model using **Keras**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential([\n",
    "    layers.Dense(100, activation='relu', input_shape=[57], name='hidden_layer1'),\n",
    "    layers.Dropout(0.3),  # Ajout d'une couche Dropout pour rÃ©duire le surajustement\n",
    "    layers.Dense(100, activation='relu', name='hidden_layer2'),\n",
    "    layers.Dropout(0.3),  # Ajout d'une couche Dropout pour rÃ©duire le surajustement\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1, activation='sigmoid', name='output_layer'),  # Changement de l'activation en 'sigmoid'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer1 (Dense)       (None, 100)               5800      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,401\n",
      "Trainable params: 16,201\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 2:</font></b>\n",
    " \n",
    "- Precise the `optimizer`, the `loss-fonction` & the `metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 3:</font></b>\n",
    " \n",
    "- Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ELITEBOOK\\anaconda3\\envs\\ner\\lib\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 3s 12ms/step - loss: 0.7049 - accuracy: 0.6382 - val_loss: 0.6192 - val_accuracy: 0.7284\n",
      "Epoch 2/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6444 - accuracy: 0.6726 - val_loss: 0.5698 - val_accuracy: 0.6978\n",
      "Epoch 3/50\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6181 - accuracy: 0.6870 - val_loss: 0.5675 - val_accuracy: 0.7012\n",
      "Epoch 4/50\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.6021 - accuracy: 0.6854 - val_loss: 0.5608 - val_accuracy: 0.7029\n",
      "Epoch 5/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.5932 - accuracy: 0.6960 - val_loss: 0.5441 - val_accuracy: 0.7131\n",
      "Epoch 6/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.5799 - accuracy: 0.6887 - val_loss: 0.5468 - val_accuracy: 0.7046\n",
      "Epoch 7/50\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5569 - accuracy: 0.7176 - val_loss: 0.5446 - val_accuracy: 0.7097\n",
      "Epoch 8/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.5567 - accuracy: 0.7138 - val_loss: 0.5351 - val_accuracy: 0.7114\n",
      "Epoch 9/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7223 - val_loss: 0.5563 - val_accuracy: 0.7012\n",
      "Epoch 10/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7499 - val_loss: 0.5653 - val_accuracy: 0.6961\n",
      "Epoch 11/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7554 - val_loss: 0.5218 - val_accuracy: 0.7114\n",
      "Epoch 12/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7652 - val_loss: 0.5502 - val_accuracy: 0.6978\n",
      "Epoch 13/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7690 - val_loss: 0.5110 - val_accuracy: 0.7046\n",
      "Epoch 14/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7949 - val_loss: 0.5281 - val_accuracy: 0.7131\n",
      "Epoch 15/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7970 - val_loss: 0.4763 - val_accuracy: 0.7453\n",
      "Epoch 16/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8102 - val_loss: 0.4872 - val_accuracy: 0.7453\n",
      "Epoch 17/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7958 - val_loss: 0.5959 - val_accuracy: 0.6893\n",
      "Epoch 18/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8301 - val_loss: 0.4264 - val_accuracy: 0.7674\n",
      "Epoch 19/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8297 - val_loss: 0.5074 - val_accuracy: 0.7012\n",
      "Epoch 20/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8251 - val_loss: 0.4346 - val_accuracy: 0.7521\n",
      "Epoch 21/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8382 - val_loss: 0.4317 - val_accuracy: 0.7504\n",
      "Epoch 22/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.8497 - val_loss: 0.3986 - val_accuracy: 0.7776\n",
      "Epoch 23/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8420 - val_loss: 0.3711 - val_accuracy: 0.8302\n",
      "Epoch 24/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.3387 - accuracy: 0.8505 - val_loss: 0.4369 - val_accuracy: 0.7827\n",
      "Epoch 25/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.8671 - val_loss: 0.4359 - val_accuracy: 0.7572\n",
      "Epoch 26/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.3135 - accuracy: 0.8709 - val_loss: 0.4603 - val_accuracy: 0.7521\n",
      "Epoch 27/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.3159 - accuracy: 0.8667 - val_loss: 0.3804 - val_accuracy: 0.8370\n",
      "Epoch 28/50\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8794 - val_loss: 0.4106 - val_accuracy: 0.7929\n",
      "Epoch 29/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.3107 - accuracy: 0.8709 - val_loss: 0.3287 - val_accuracy: 0.8574\n",
      "Epoch 30/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8769 - val_loss: 0.3398 - val_accuracy: 0.8710\n",
      "Epoch 31/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2928 - accuracy: 0.8866 - val_loss: 0.3268 - val_accuracy: 0.8540\n",
      "Epoch 32/50\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.2976 - accuracy: 0.8760 - val_loss: 0.2998 - val_accuracy: 0.8930\n",
      "Epoch 33/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.8947 - val_loss: 0.2891 - val_accuracy: 0.8829\n",
      "Epoch 34/50\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.8862 - val_loss: 0.2890 - val_accuracy: 0.8812\n",
      "Epoch 35/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2668 - accuracy: 0.8845 - val_loss: 0.3124 - val_accuracy: 0.9015\n",
      "Epoch 36/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.8883 - val_loss: 0.2769 - val_accuracy: 0.8879\n",
      "Epoch 37/50\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.2766 - accuracy: 0.8934 - val_loss: 0.2587 - val_accuracy: 0.9168\n",
      "Epoch 38/50\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.8955 - val_loss: 0.2858 - val_accuracy: 0.8761\n",
      "Epoch 39/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2765 - accuracy: 0.8934 - val_loss: 0.2559 - val_accuracy: 0.9134\n",
      "Epoch 40/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.9023 - val_loss: 0.2858 - val_accuracy: 0.9032\n",
      "Epoch 41/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2530 - accuracy: 0.9049 - val_loss: 0.3344 - val_accuracy: 0.8693\n",
      "Epoch 42/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2511 - accuracy: 0.9096 - val_loss: 0.2323 - val_accuracy: 0.9338\n",
      "Epoch 43/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2435 - accuracy: 0.9062 - val_loss: 0.2809 - val_accuracy: 0.9117\n",
      "Epoch 44/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.9062 - val_loss: 0.2732 - val_accuracy: 0.9015\n",
      "Epoch 45/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2423 - accuracy: 0.9113 - val_loss: 0.2485 - val_accuracy: 0.9236\n",
      "Epoch 46/50\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.2358 - accuracy: 0.9096 - val_loss: 0.2292 - val_accuracy: 0.9338\n",
      "Epoch 47/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2225 - accuracy: 0.9108 - val_loss: 0.2084 - val_accuracy: 0.9406\n",
      "Epoch 48/50\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.2187 - accuracy: 0.9134 - val_loss: 0.2207 - val_accuracy: 0.9321\n",
      "Epoch 49/50\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.2252 - accuracy: 0.9163 - val_loss: 0.2772 - val_accuracy: 0.9066\n",
      "Epoch 50/50\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.2137 - accuracy: 0.9253 - val_loss: 0.2223 - val_accuracy: 0.9372\n"
     ]
    }
   ],
   "source": [
    "hist = model1.fit(X_train,\n",
    "                 y_train,\n",
    "                 batch_size=32,\n",
    "                 epochs=50,\n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>PS :</font></b> The accuracy of our model on the validation data is **93%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.679268</td>\n",
       "      <td>0.646739</td>\n",
       "      <td>0.597993</td>\n",
       "      <td>0.733696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.612044</td>\n",
       "      <td>0.689198</td>\n",
       "      <td>0.617314</td>\n",
       "      <td>0.676630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585873</td>\n",
       "      <td>0.700408</td>\n",
       "      <td>0.598776</td>\n",
       "      <td>0.682065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566632</td>\n",
       "      <td>0.711617</td>\n",
       "      <td>0.569040</td>\n",
       "      <td>0.717391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545494</td>\n",
       "      <td>0.727921</td>\n",
       "      <td>0.553915</td>\n",
       "      <td>0.703804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.679268  0.646739  0.597993      0.733696\n",
       "1  0.612044  0.689198  0.617314      0.676630\n",
       "2  0.585873  0.700408  0.598776      0.682065\n",
       "3  0.566632  0.711617  0.569040      0.717391\n",
       "4  0.545494  0.727921  0.553915      0.703804"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(hist.history)\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tracer la courbe de la fonction loss (pour l'entrainement et la validation) en fonction du nombre d'epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss: 0.20647987723350525\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Keras$ $tuner$ : (Le deuxiÃ¨me modÃ¨le en optimisant les hyperparamÃ¨tres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons utiliser **Keras Tuner** pour effectuer une recherche d'hyperparamÃ¨tres pour un modÃ¨le de rÃ©seau de neurones. Le but de cette parrtie est de trouver les meilleures **valeurs** d'hyperparamÃ¨tres pour maximiser la prÃ©cision (`accuracy`) du modÃ¨le sur un ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 24s]\n",
      "val_accuracy: 0.91032608350118\n",
      "\n",
      "Best val_accuracy So Far: 0.91032608350118\n",
      "Total elapsed time: 00h 03m 58s\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Fonction construisant et configurant un modÃ¨le de rÃ©seau de neurones \n",
    "    en fonction des hyperparamÃ¨tres spÃ©cifiÃ©s.\n",
    "\n",
    "    Parameters \n",
    "    ----------\n",
    "    hp : de type HyperParameters fourni par Keras Tuner. Il est utilisÃ© pour spÃ©cifier les valeurs des hyperparamÃ¨tres du modÃ¨le. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : est une instance de Sequential dans Keras, reprÃ©sentant le modÃ¨le de rÃ©seau de neurones configurÃ© avec les \n",
    "    hyperparamÃ¨tres spÃ©cifiÃ©s.\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('units1', min_value=150, max_value=200, step=20),\n",
    "                           activation='relu', input_shape=[57], name='hidden_layer1'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(units=hp.Int('units2', min_value=100, max_value=200, step=20),\n",
    "                           activation='relu', name='hidden_layer2'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(1, activation='sigmoid', name='output_layer'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "        hp.Choice('learning_rate', values=[1e-2, 1e-1])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Choisissez le nombre d'essais que vous voulez\n",
    "    executions_per_trial=3,  # Nombre d'exÃ©cutions par essai pour rÃ©duire la variabilitÃ©\n",
    "    directory='my_dir2',\n",
    "    project_name='keras_tuner2'\n",
    ")\n",
    "\n",
    "print('Le rÃ©sumÃ© des hyperparamÃ¨tres et de leur espace de recherche :', tuner.search_space_summary() ) # Afficher un rÃ©sumÃ© de l'espace de recherche des hyperparamÃ¨tres\n",
    "#lanÃ§ons la recherche d'hyperparamÃ¨tres en utilisant l'ensemble d'entraÃ®nement (X_train, y_train) et l'ensemble de validation (X_val, y_val).\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=10,\n",
    "             validation_data=(X_val, y_val)) \n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0] #renvoie les meilleurs modÃ¨les\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0] #renvoie les meilleurs hyperparamÃ¨tres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les valeurs des hyperparamÃ¨tres du meilleur modele :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamÃ¨tres:\n",
      "Units1: 170\n",
      "Units2: 160\n",
      "Learning Rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs hyperparamÃ¨tres:\")\n",
    "print(f\"Units1: {best_hyperparameters.get('units1')}\")\n",
    "# print(f\"Dropout1: {best_hyperparameters.get('dropout1')}\")\n",
    "print(f\"Units2: {best_hyperparameters.get('units2')}\")\n",
    "# print(f\"Dropout2: {best_hyperparameters.get('dropout2')}\")\n",
    "print(f\"Learning Rate: {best_hyperparameters.get('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La validation accuracy du meilleur modele :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/23 [>.............................] - ETA: 0s - loss: 0.2183 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.9171\n",
      "Validation Accuracy du meilleur modÃ¨le : 0.917119562625885\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = best_model.evaluate(X_val, y_val)[1]\n",
    "print(f\"Validation Accuracy du meilleur modÃ¨le : {validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer1 (Dense)       (None, 170)               9860      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 170)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 160)               27360     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 160)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 160)              640       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,021\n",
      "Trainable params: 37,701\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer1 (Dense)       (None, 100)               5800      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,401\n",
      "Trainable params: 16,201\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir2\\keras_tuner2\n",
      "Showing 5 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units1: 170\n",
      "units2: 160\n",
      "learning_rate: 0.01\n",
      "Score: 0.91032608350118\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units1: 170\n",
      "units2: 200\n",
      "learning_rate: 0.01\n",
      "Score: 0.9026267925898234\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units1: 170\n",
      "units2: 140\n",
      "learning_rate: 0.01\n",
      "Score: 0.8999094168345133\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units1: 190\n",
      "units2: 180\n",
      "learning_rate: 0.01\n",
      "Score: 0.8917572498321533\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units1: 150\n",
      "units2: 180\n",
      "learning_rate: 0.01\n",
      "Score: 0.8894927501678467\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary(num_trials=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Evaluate$ $Our$ $Models$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 1:</font></b>\n",
    " \n",
    "- Transform our data into a numpy/list data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.values\n",
    "\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"skyblue\">Step 2:</font></b>\n",
    " \n",
    "- Evaluate our model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/29 [>.............................] - ETA: 1s - loss: 0.2625 - accuracy: 0.8750"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2157 - accuracy: 0.9283\n",
      "Loss on test data: 0.21574437618255615\n",
      "Accuracy on test data: 0.9283387660980225\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy_DNN = model1.evaluate(X_test, y_test)\n",
    "print('Loss on test data:', loss)\n",
    "print('Accuracy on test data:', accuracy_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/29 [>.............................] - ETA: 1s - loss: 0.2865 - accuracy: 0.8438"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9142\n",
      "Loss on test data: 0.2485089898109436\n",
      "Accuracy on test data: 0.9142236709594727\n"
     ]
    }
   ],
   "source": [
    "loss2, accuracy_DNN2 = best_model.evaluate(X_test, y_test)\n",
    "print('Loss on test data:', loss2)\n",
    "print('Accuracy on test data:', accuracy_DNN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=red> RÃ©sultat : </font></b>\n",
    "\n",
    "- Le `premier modÃ¨le` est plus <b>performant</b> que le deuxiÃ¨me.\n",
    "\n",
    "<b><font color=blue> Explication : </font></b>\n",
    "\n",
    "Normalement, le deuxiÃ¨ment doit Ãªtre **plus performant** que le premier ou au moins donne **les mÃªmes** rÃ©sultats que le premier parce que les hyperparamÃ¨tres du premier modÃ¨le appartient Ã  l'espace de recherche dans le deuxiÃ¨me modÃ¨le, du coup, ces resultats peuvent revenir Ã  autres causes :\n",
    "\n",
    "- `Nombre d'essais insuffisant` : Il est possible que le nombre d'essais (max_trials) que vous avez spÃ©cifiÃ© pour le tuner ne soit pas suffisant pour explorer de maniÃ¨re exhaustive l'espace des hyperparamÃ¨tres.\n",
    "\n",
    "- `Surajustement Ã  l'ensemble de validation` : Le tuner peut choisir des hyperparamÃ¨tres qui surajustent Ã  l'ensemble de validation. Cela peut entraÃ®ner de bonnes performances sur l'ensemble de validation, mais des performances infÃ©rieures sur de nouveaux exemples.\n",
    "\n",
    "- `Interaction complexe entre hyperparamÃ¨tres` : Parfois, l'interaction entre diffÃ©rents hyperparamÃ¨tres peut Ãªtre complexe, et le tuner peut ne pas Ãªtre en mesure de trouver la meilleure combinaison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Predict$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for each class\n",
    "predictions_proba = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to predicted labels (0 or 1 in this binary classification case)\n",
    "predictions = (predictions_proba > 0.5).astype(int)\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predicted probabilities:\", predictions_proba[:10])  # Display the predicted probabilities for the first 10 samples\n",
    "print(\"Predicted labels:\", predictions[:10])  # Display the predicted labels for the first 10 samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Logistic$ $regression$\n",
    "We're gonna use the same set of X_train, X_test, y_train and y_test data in the first section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the logistique regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model_v1 = LogisticRegression(random_state=16, max_iter=1000, solver='lbfgs', C=0.1).fit(X_train, y_train)\n",
    "#predicted values\n",
    "y_pred = logistic_model_v1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the confusion matrix\n",
    "# import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['not spam', 'spam']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# PrÃ©diction sur l'ensemble d'entraÃ®nement et de validation\n",
    "y_train_pred = logistic_model_v1.predict(X_train)\n",
    "\n",
    "y_test_pred = logistic_model_v1.predict(X_test)\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Accuracy sur l'ensemble d'entraÃ®nement : {train_accuracy}\")\n",
    "\n",
    "print(f\"Accuracy sur l'ensemble de validation : {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logistic_model_v1.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation croisÃ©e \n",
    "Nous allons utilisÃ© **GridSearchCV**  pour trouver les meilleurs hyperparamÃ¨tres d'un modÃ¨le tout en utilisant la validation croisÃ©e pour Ã©valuer les performances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#model\n",
    "logisticReg = LogisticRegression()\n",
    "\n",
    "# Grille des hyperparamÃ¨tres Ã  explorer\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [500, 1000]\n",
    "}\n",
    "\n",
    "# CrÃ©ation de l'objet GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=logistic_model, param_grid=param_grid, cv=6, scoring='accuracy')\n",
    "\n",
    "# ExÃ©cution de la recherche par grille avec validation croisÃ©e\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# RÃ©cupÃ©ration des meilleurs hyperparamÃ¨tres et du meilleur score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Meilleurs hyperparamÃ¨tres :\", best_params)\n",
    "print(\"Meilleur score obtenu :\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix final des hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(penalty='l1', max_iter=500, solver='liblinear', C=10, random_state=16).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation du modÃ¨le finale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['not spam', 'spam']\n",
    "accuracy_LR_test = accuracy_score(y_test, y_pred)\n",
    "print(\"PrÃ©cision du modÃ¨le :\", accuracy_LR_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# PrÃ©diction sur l'ensemble d'entraÃ®nement et de validation\n",
    "y_train_pred = logistic_model.predict(X_train)\n",
    "\n",
    "y_test_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Accuracy sur l'ensemble d'entraÃ®nement : {train_accuracy}\")\n",
    "\n",
    "print(f\"Accuracy sur l'ensemble de validation : {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logistic_model.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\" auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ResumÃ© :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "models=[logistic_model_v1,logistic_model]\n",
    "y_pred_v1=logistic_model_v1.predict(X_test)\n",
    "y_pred_v2=logistic_model.predict(X_test)\n",
    "y_pred=[y_pred_v1,y_pred_v2]\n",
    "Metrics=pd.DataFrame({\n",
    "    i:[accuracy_score(y_test,j),\n",
    "    precision_score(j,y_test),\n",
    "    recall_score(j, y_test),\n",
    "    f1_score(j,y_test)] \n",
    "    for i,j in zip (models,y_pred)},\n",
    "    index=['Accuracy','Precision','Recall','F1'])\n",
    "Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=red> RÃ©sultat : </font></b>\n",
    "\n",
    "- AprÃ¨s que nous avons utilisÃ© la validation croisÃ©e nous avons eu des meilleurs rÃ©sultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Initialisation du modÃ¨le de Gradient Boosting Classifier\n",
    "gradient_boosting_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# EntraÃ®nement du modÃ¨le sur les donnÃ©es d'entraÃ®nement\n",
    "gradient_boosting_model.fit(X_train, y_train)\n",
    "\n",
    "# PrÃ©diction sur les donnÃ©es de test\n",
    "y_pred = gradient_boosting_model.predict(X_test)\n",
    "\n",
    "# Ã‰valuation des performances du modÃ¨le\n",
    "target_names = ['not spam', 'spam']\n",
    "accuracy_GB_test = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred,target_names=target_names)\n",
    "\n",
    "print(\"PrÃ©cision du modÃ¨le :\", accuracy_GB_test)\n",
    "print(\"Rapport de classification :\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Three best models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy logistic regression :{accuracy_LR_test},accuracy DNN {accuracy_DNN}, accuracy Gradient boosting {accuracy_GB_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "models=[model,logistic_model,gradient_boosting_model]\n",
    "y_pred_model=model.predict(X_test)\n",
    "y_pred_model = (y_pred_model > 0.5).astype(int)\n",
    "y_pred_logistic=logistic_model.predict(X_test)\n",
    "y_pred_gradb=gradient_boosting_model.predict(X_test)\n",
    "\n",
    "y_pred=[y_pred_model,y_pred_logistic, y_pred_gradb]\n",
    "Metrics=pd.DataFrame({\n",
    "    str(i):[accuracy_score(y_test,j),\n",
    "    precision_score(j,y_test),\n",
    "    recall_score(j, y_test),\n",
    "    f1_score(j,y_test)] \n",
    "    for i,j in zip (models,y_pred)},\n",
    "    index=['Accuracy','Precision','Recall','F1'])\n",
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
